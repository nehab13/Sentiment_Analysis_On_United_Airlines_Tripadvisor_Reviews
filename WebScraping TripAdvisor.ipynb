{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from selenium import webdriver\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default path to file to store data\n",
    "path_to_file = \"/Users/neha/Documents/Projects for Resume/reviews.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of pages to be scraped\n",
    "num_page = 1001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of Tripadvisor United Airlines review\n",
    "url = \"https://www.tripadvisor.com/Airline_Review-d8729177-Reviews-United-Airlines\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the webdriver\n",
    "PATH = \"/Users/neha/Downloads/chromedriver\" #location of the chromedriver\n",
    "browser = webdriver.Chrome(PATH) \n",
    "browser.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the reviews in csv file\n",
    "csvFile = open(path_to_file, 'a', encoding=\"utf-8\")\n",
    "csvWriter = csv.writer(csvFile)\n",
    "csvWriter.writerow([\"Date\", \"Rating\", \"Title\",\"Reviews\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterating through all the pages\n",
    "for i in range(0, num_page):\n",
    "\n",
    "   #sleep to wait for the page to be loaded\n",
    "    time.sleep(5)\n",
    "    browser.find_element_by_xpath(\".//div[contains(@data-test-target, 'expand-review')]\").click()\n",
    "\n",
    "    container = browser.find_elements_by_xpath(\"//div[@data-reviewid]\") #container which contains all the info\n",
    "    dates = browser.find_elements_by_xpath(\".//div[@class='_2fxQ4TOx']\") #date when the review is wrote\n",
    "\n",
    "    for j in range(len(container)):\n",
    "\n",
    "        rating = container[j].find_element_by_xpath(\".//span[contains(@class, 'ui_bubble_rating bubble_')]\").get_attribute(\"class\").split(\"_\")[3]\n",
    "        title = container[j].find_element_by_xpath(\".//div[contains(@data-test-target, 'review-title')]\").text\n",
    "        review = container[j].find_element_by_xpath(\".//q[@class='IRsGHoPm']\").text.replace(\"\\n\", \"  \")\n",
    "        date = \" \".join(dates[j].text.split(\" \")[-2:])\n",
    "    \n",
    "        csvWriter.writerow([date, rating, title, review]) \n",
    "        \n",
    "    # change the page            \n",
    "    next_page = browser.find_element_by_xpath('.//a[@class=\"ui_button nav next primary \"]')\n",
    "    browser.implicitly_wait(10) # wait added as the page number were getting covered\n",
    "    next_page.click()\n",
    "\n",
    "browser.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
